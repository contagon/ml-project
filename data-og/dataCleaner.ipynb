{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for downloading then unzipping the data files\n",
    "~~~\n",
    "pip install kaggle\n",
    "export KAGGLE_USERNAME=eastonpotokar\n",
    "export KAGGLE_KEY=1bfd140356aae8ffd62b234617295b77\n",
    "kaggle datasets download -d shuyangli94/food-com-recipes-and-user-interactions\n",
    "unzip food-com-recipes-and-user-interactions.zip\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean out the Recipes Dataset, extracting the items that we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save map from ingredients id to ingredients\n",
    "maps = pickle.load( open('ingr_map.pkl', 'rb') )\n",
    "ing_decoder = {i['id']: i['replaced'] for index, i in maps.iterrows()}\n",
    "pickle.dump(ing_decoder, open(\"../data-cleaned/ingredient_decoder.pkl\", \"wb\"))\n",
    "\n",
    "#we put recipes into similar format as our dataset\n",
    "pp_recipes = pd.read_csv('PP_recipes.csv')\n",
    "raw_recipes = pd.read_csv('RAW_recipes.csv')\n",
    "recipes = pd.merge(pp_recipes, raw_recipes, on='id')\n",
    "\n",
    "#clean and get tags all ready\n",
    "tags = set()\n",
    "for i in raw_recipes.tags:\n",
    "    tags.update( json.loads(i.replace(\"'\", '\"')) )\n",
    "    \n",
    "tags = sorted(list(tags))\n",
    "tag_encoder = {tag: i for i, tag in enumerate(tags)}\n",
    "tag_decoder = {i: tag for i, tag in enumerate(tags)}\n",
    "pickle.dump(tag_decoder, open(\"../data-cleaned/tag_decoder.pkl\", \"wb\"))\n",
    "\n",
    "#also make a recipe decoder\n",
    "recipe_decoder = {i['i']: i['name'] for _, i in recipes.iterrows()}\n",
    "pickle.dump(recipe_decoder, open(\"../data-cleaned/recipe_decoder.pkl\", \"wb\"))\n",
    "\n",
    "num_rec = len(list(recipes['i']))\n",
    "num_ing = max(ing_decoder.keys())\n",
    "num_tags = max(tag_decoder.keys())\n",
    "num_others = 2 #calories and minutes\n",
    "\n",
    "#iterate through, saving the tags and ingredients\n",
    "row_recipe = []\n",
    "column_item = []\n",
    "for _, recipe in recipes.iterrows():\n",
    "    #get all ingredients\n",
    "    for i in json.loads(recipe['ingredient_ids']):\n",
    "        row_recipe.append(recipe['i'])\n",
    "        column_item.append(i)\n",
    "    #get all tags\n",
    "    for j in json.loads(recipe['tags'].replace(\"'\", '\"')):\n",
    "        row_recipe.append(recipe['i'])\n",
    "        column_item.append(tag_encoder[j] + num_ing)\n",
    "\n",
    "#one of each ingredient and tag added\n",
    "counts = [1]*len(row_recipe)\n",
    "\n",
    "#add in minutes\n",
    "row_recipe += list(recipes['i'])\n",
    "column_item += [num_ing+num_tags]*len(list(recipes.index))\n",
    "counts += list(recipes[\"minutes\"])\n",
    "\n",
    "#add in calories\n",
    "row_recipe += list(recipes['i'])\n",
    "column_item += [num_ing+num_tags+1]*len(list(recipes.index))\n",
    "counts += [json.loads(i)[0] for i in list(recipes['nutrition'])]\n",
    "\n",
    "X = sparse.csr_matrix((counts, [row_recipe, column_item]), shape=(num_rec, num_ing + num_tags + num_others), dtype=np.float)\n",
    "\n",
    "sparse.save_npz('../data-cleaned/recipes.npz', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go through the users dataset, extracting what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we'll load all the data\n",
    "user_train = pd.read_csv('interactions_train.csv')\n",
    "user_valid = pd.read_csv('interactions_validation.csv')\n",
    "user_test  = pd.read_csv('interactions_test.csv')\n",
    "\n",
    "num_user = max(user_train['u'].max(), user_valid['u'].max(), user_test['u'].max())+1\n",
    "\n",
    "#TRAIN SET save the user number, recipe and rating\n",
    "row_user = list(user_train['u'])\n",
    "column_rec = list(user_train['i'])\n",
    "rating = list(user_train['rating'])\n",
    "\n",
    "#make and save\n",
    "X = sparse.csr_matrix((rating, [row_user, column_rec]), shape=(num_user, num_rec), dtype=np.float)\n",
    "sparse.save_npz('../data-cleaned/user_train.npz', X)\n",
    "\n",
    "#TRAIN SET save the user number, recipe and rating\n",
    "temp = pd.concat((user_valid, user_test))\n",
    "row_user = list(np.arange(len(temp))) * 2\n",
    "column_rec = list(temp['i']) + [0]*len(temp)\n",
    "rating = list(temp['rating']) + list(temp['u']) \n",
    "\n",
    "#make and save\n",
    "X = sparse.csr_matrix((rating, [row_user, column_rec]), shape=(len(temp), num_rec+1), dtype=np.float)\n",
    "sparse.save_npz('../data-cleaned/user_test.npz', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Check User Arrays to make sure they seem right!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to decode tags from array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4-hours-or-less',\n",
       " '5-ingredients-or-less',\n",
       " 'asian',\n",
       " 'course',\n",
       " 'cuisine',\n",
       " 'dietary',\n",
       " 'easy',\n",
       " 'indian',\n",
       " 'main-ingredient',\n",
       " 'occasion',\n",
       " 'pasta-rice-and-grains',\n",
       " 'preparation',\n",
       " 'rice',\n",
       " 'side-dishes',\n",
       " 'time-to-make',\n",
       " 'vegan',\n",
       " 'vegetarian']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sparse.load_npz(\"../data-cleaned/recipes.npz\")\n",
    "tags = X[23].nonzero()[1]\n",
    "tags = tags[tags>num_ing][:-2] - num_ing\n",
    "[tag_decoder[i] for i in tags[:-1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
