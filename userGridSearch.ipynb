{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, SparsePCA, KernelPCA, LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans, SpectralClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from searchgrid import set_grid, make_grid_search, make_pipeline\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load everything\n",
    "num_ing = 8023\n",
    "recipe_decoder = pickle.load( open('data-cleaned/recipe_decoder.pkl', 'rb') )\n",
    "ingr_decoder   = pickle.load( open('data-cleaned/ingredient_decoder.pkl', 'rb') )\n",
    "tag_decoder    = pickle.load( open('data-cleaned/tag_decoder.pkl', 'rb') )\n",
    "X     = sparse.load_npz(\"data-cleaned/recipes.npz\")\n",
    "Xhat  = sparse.load_npz(\"data-cleaned/recipes_tfidf.npz\")\n",
    "U     = sparse.load_npz(\"data-cleaned/user_train.npz\")\n",
    "Uhat  = sparse.load_npz(\"data-cleaned/user_train_tfidf.npz\")\n",
    "Utest = sparse.load_npz(\"data-cleaned/user_test.npz\")\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make y data for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test = Utest[:,-1].toarray().flatten().astype('int')\n",
    "y = np.zeros((Utest.shape[0], 2), dtype='int')-1\n",
    "for i in range(len(y)):\n",
    "    recipes = Utest[i].nonzero()[1][:-1]\n",
    "    if len(recipes) == 1:\n",
    "        y[i,0] = recipes\n",
    "    elif len(recipes) == 2:\n",
    "        y[i,:] = recipes\n",
    "    else:\n",
    "        raise ValueError(\"Someone reviewed 3 recipes!\")\n",
    "\n",
    "y_blank = np.zeros((U.shape[0], 2))\n",
    "\n",
    "U_tog = sparse.vstack([U[user_test], U])\n",
    "y_tog = np.concatenate([y, y_blank])\n",
    "\n",
    "test_fold = np.concatenate([\n",
    "    # The training data.\n",
    "    np.full(U[user_test].shape[0], 0, dtype=np.int8),\n",
    "    # The development data.\n",
    "    np.full(U.shape[0], -1, dtype=np.int8)\n",
    "])\n",
    "cv = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll split whole process into 3\n",
    "\n",
    "  1. Dimension Reduction\n",
    "  2. Get nearest options\n",
    "  3. Choose 5 best from that set\n",
    "  4. Scoring\n",
    "\n",
    "Some of these will cover both (3) and (4). We'll use sklearn Pipeline to get things done. Our methods will just take a little tweaking, but we can make them work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Functions and Recommender Class - we'll inherit from it as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_score(i, js):\n",
    "    score = np.zeros_like(js)\n",
    "    #iterate through all recommendations\n",
    "    for n, j in enumerate(js):\n",
    "        #if didn't make enough recommendations, counts as 0\n",
    "        if j == -1:\n",
    "            continue\n",
    "        temp = X[i, :-1] + X[j, :-1]\n",
    "        score[n] = np.count_nonzero(temp.data==2) + int(X[i,-1]==X[j,-1])\n",
    "    return score\n",
    "\n",
    "def recommend_scoring(y_true, y_pred):\n",
    "    max_scores = np.zeros_like(y_pred)\n",
    "    #iterate through all data\n",
    "    for i, (yi, y_predi) in enumerate(zip(y_true, y_pred)):\n",
    "        #iterate through each liked recipe to find closest\n",
    "        for l in yi:\n",
    "            if l == -1:\n",
    "                continue\n",
    "            max_scores[i] = np.maximum(max_scores[i], recipe_score(l, y_predi))\n",
    "            \n",
    "    return max_scores.mean(axis=1)\n",
    "\n",
    "class Recommender(BaseEstimator):\n",
    "    def score(self, X, y):\n",
    "        return recommend_scoring(y, self.predict(X)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make all Recommender Classes Here - Easy to add more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNNRecommender(Recommender):\n",
    "    def __init__(self, n_neighbors=5, metric='minkowski', algorithm='brute'):\n",
    "        self.n_neighbors = n_neighbors #add one to exclude ourself\n",
    "        self.metric      = metric\n",
    "        self.algorithm   = algorithm\n",
    "        self.estimator   = NearestNeighbors(n_neighbors=self.n_neighbors+1, metric=metric, algorithm = algorithm)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.estimator.fit(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        #find closest users\n",
    "        idxs = self.estimator.kneighbors(X)[1][:,1:]\n",
    "\n",
    "        rec_recipes = np.zeros((X.shape[0], 5), dtype='int')\n",
    "        #iterate through each user's closest users\n",
    "        for i, idx in enumerate(idxs):\n",
    "            #find their liked recipes\n",
    "            close_recipes = U[idx].nonzero()[1]\n",
    "            #and find 5 most common ones to recommend\n",
    "            rec_recipe   = Counter(close_recipes).most_common(5)\n",
    "            #sometimes there's not 5 recommendations - make due\n",
    "            if len(rec_recipe) < 5:\n",
    "                rec_recipes[i] = np.array([k[0] for k in rec_recipe] + [-1]*(5-len(rec_recipe)))\n",
    "            else:\n",
    "                rec_recipes[i]   = np.array([k[0] for k in rec_recipe][:5])\n",
    "\n",
    "        return rec_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterRecommender(Recommender):\n",
    "    def __init__(self, clusterer=KMeans(), n_clusters=10):\n",
    "        self.n_clusters  = n_clusters\n",
    "        self.clusterer   = clusterer\n",
    "        self.clusterer.n_clusters = self.n_clusters\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.labels = self.clusterer.fit_predict(X)\n",
    "#         self.labels = self.clusterer.predict(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        #find closest users\n",
    "        labels = self.clusterer.predict(X)\n",
    "\n",
    "        rec_recipes = np.zeros((X.shape[0], 5), dtype='int')\n",
    "        #iterate through each user's cluster\n",
    "        for i, label in enumerate(labels):\n",
    "            #find all recipes in cluster\n",
    "            idx = np.argwhere(self.labels==label).flatten()\n",
    "            #find their liked recipes\n",
    "            close_recipes = U[idx].nonzero()[1]\n",
    "            #and find 5 most common ones to recommend\n",
    "            rec_recipe   = Counter(close_recipes).most_common(5)\n",
    "            #sometimes there's not 5 recommendations - make due\n",
    "            if len(rec_recipe) < 5:\n",
    "                rec_recipes[i] = np.array([k[0] for k in rec_recipe] + [-1]*(5-len(rec_recipe)))\n",
    "            else:\n",
    "                rec_recipes[i]   = np.array([k[0] for k in rec_recipe][:5])\n",
    "\n",
    "        return rec_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterNNRecommender(Recommender):\n",
    "    def __init__(self, clusterer=KMeans(), n_clusters=10, n_neighbors=5):\n",
    "        self.n_clusters  = n_clusters\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.clusterer   = clusterer\n",
    "        self.clusterer.n_clusters = self.n_clusters\n",
    "        self.knn         = NearestNeighbors(n_neighbors=self.n_neighbors+1)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.X = X\n",
    "        self.labels = self.clusterer.fit_predict(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        #find closest users\n",
    "        labels = self.clusterer.predict(X)\n",
    "\n",
    "        rec_recipes = np.zeros((X.shape[0], 5), dtype='int')\n",
    "        #iterate through each user's cluster\n",
    "        for i, (label, x) in enumerate(zip(labels, X)):\n",
    "            #find all recipes in cluster\n",
    "            cluster = np.argwhere(self.labels==label).flatten()\n",
    "\n",
    "            #find k nearest neighbors in the cluster (unless there isn't enough of them)\n",
    "            if len(cluster) > self.n_neighbors+1:\n",
    "                idx = self.knn.fit(self.X[cluster]).kneighbors(x.reshape(1,-1))[1][0,1:]\n",
    "            else:\n",
    "                idx = cluster\n",
    "                \n",
    "            #find their liked recipes\n",
    "            close_recipes = U[idx].nonzero()[1]\n",
    "            #and find 5 most common ones to recommend\n",
    "            rec_recipe   = Counter(close_recipes).most_common(5)\n",
    "            #sometimes there's not 5 recommendations - make due\n",
    "            if len(rec_recipe) < 5:\n",
    "                rec_recipes[i] = np.array([k[0] for k in rec_recipe] + [-1]*(5-len(rec_recipe)))\n",
    "            else:\n",
    "                rec_recipes[i]   = np.array([k[0] for k in rec_recipe][:5])\n",
    "\n",
    "        return rec_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNRadiusRecommender(Recommender):\n",
    "    def __init__(self, radius=1, metric='minkowski', algorithm='brute'):\n",
    "        self.radius    = radius\n",
    "        self.metric    = metric\n",
    "        self.algorithm = algorithm\n",
    "        self.estimator = NearestNeighbors(radius=self.radius, metric=metric, algorithm = algorithm)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.estimator.fit(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        #find closest users\n",
    "        distances, idxs = self.estimator.radius_neighbors(X)\n",
    "\n",
    "        rec_recipes = np.zeros((X.shape[0], 5), dtype='int')\n",
    "        #iterate through each user's closest users\n",
    "        for i, (distance, idx) in enumerate(zip(distances, idxs)):\n",
    "            #find their liked recipes (making sure to exclude ourself)\n",
    "            close_recipes = U[idx[distance!=0]].nonzero()[1]\n",
    "            #and find 5 most common ones to recommend\n",
    "            rec_recipe   = Counter(close_recipes).most_common(5)\n",
    "            #sometimes there's not 5 recommendations - make due\n",
    "            if len(rec_recipe) < 5:\n",
    "                rec_recipes[i] = np.array([k[0] for k in rec_recipe] + [-1]*(5-len(rec_recipe)))\n",
    "            else:\n",
    "                rec_recipes[i]   = np.array([k[0] for k in rec_recipe][:5])\n",
    "\n",
    "        return rec_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"dr\", TruncatedSVD(n_components=10)),\n",
    "                (\"rdr\", ClusterRecommender(clusterer=SpectralClustering(), n_clusters=5))])\n",
    "\n",
    "pipe.fit(U)\n",
    "pipe.score(U[user_test][:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"dr\", TruncatedSVD()),\n",
    "                (\"rdr\", ClusterRecommender())])\n",
    "\n",
    "n_components = [20, 40, 60, 80]\n",
    "tsvd = set_grid(TruncatedSVD(), n_components=n_components)\n",
    "kpca = set_grid(KernelPCA(), n_components=n_components)\n",
    "nmf = set_grid(NMF(), n_components=n_components)\n",
    "spca = set_grid(SparsePCA(), n_components=n_components)\n",
    "\n",
    "n_clusters = [10, 50, 100, 150]\n",
    "n_neighbors = [2, 10, 50, 100]\n",
    "metrics = ['minkowski', 'cosine']\n",
    "knn = set_grid(kNNRecommender(), n_neighbors=n_neighbors, metric=metrics)\n",
    "nnra    = set_grid(NNRadiusRecommender(), radius=, metrics=)\n",
    "cluster = set_grid(ClusterRecommender(), clusterer=[KMeans(), GaussianMixture(), SpectralClustering()], n_clusters=n_clusters)\n",
    "dbscan  = set_grid(ClusterRecommender(), clusterer=[DBSCAN()], eps=, min_samples=)\n",
    "cluster = set_grid(ClusterNNRecommender(), clusterer=[KMeans(), GaussianMixture(), SpectralClustering()], n_clusters=n_clusters, n_neighbors=)\n",
    "dbscan  = set_grid(ClusterNNRecommender(), clusterer=[DBSCAN()], eps=, min_samples=, n_neighbors=)\n",
    "\n",
    "pipenew = set_grid(pipe, dr=[tsvd, nmf, spca], rdr=[knn, cluster])\n",
    "opt  = make_grid_search(pipenew, cv=cv, verbose=3, n_jobs=3)\n",
    "opt.fit(U_tog, y_tog)\n",
    "pickle.dump(opt.cv_results_, open(\"results.pkl\", 'wb'))\n",
    "print(opt.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"kNN\", \"NNBall\", \"KMeans\", \"GMM\", \"MinCut\", \"KMeansNN\", \"GMMNN\", \"MinCutNN\", ]\n",
    "rows = [\"PCA\", \"KPCA\", \"NMF\", \"LDA\"]\n",
    "d = pd.DataFrame(tuple(), columns=columns, index=rows)\n",
    "d.to_pickle(\"results/user_U_sum.pkl\")\n",
    "d.to_pickle(\"results/user_U_fr.pkl\")\n",
    "d.to_pickle(\"results/user_U_rf.pkl\")\n",
    "d.to_pickle(\"results/user_Uhat_sum.pkl\")\n",
    "d.to_pickle(\"results/user_Uhat_fr.pkl\")\n",
    "d.to_pickle(\"results/user_Uhat_rf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(8.572754600777182,\n 1.857438564300537,\n 47.26626968383789,\n {'dr__n_components': 20, 'rdr__n_neighbors': 2})"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"results/user_U.pkl\")[\"kNN\"][\"PCA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}